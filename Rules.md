# Financial Audio Intelligence — Project Context (rule.md)

## Purpose of This File

This file acts as the **single source of truth** for the hackathon project.

If any developer, IDE agent, or teammate is confused about:

* architecture
* workflow
* responsibilities
* data flow
* RAG pipeline
* database structure

they should refer to this file.

This project converts **financial call audio → structured insights → historical reasoning → repayment risk prediction**.

---

# Project Overview

We are building a system that:

1. Processes multilingual financial call recordings
2. Extracts structured insights using NLP
3. Stores interaction history
4. Uses RAG (Retrieval-Augmented Generation) to detect repayment patterns
5. Produces explainable repayment risk decisions
6. Can integrate into workflows (frontend or n8n)

This is NOT a speech-to-text project.
This is a **financial memory + reasoning system**.

---

# System Components

The system has three major parts:

## 1. Person-1 Service (STT + NLP Extraction)

Responsible for:

* Speech-to-text conversion
* Transcript cleanup
* Intent classification
* Sentiment detection
* Entity extraction
* Risk indicator detection
* Call summary creation

This service sends structured JSON to the RAG service.

---

## 2. RAG Service (Memory + Reasoning)

Responsible for:

* Storing call history
* Embedding call summaries
* Retrieving past interactions
* Building reasoning context
* Running LLM risk reasoning
* Updating call records

This is the **core intelligence layer**.

---

## 3. Frontend / Workflow Layer

Responsible for:

* Uploading audio
* Showing transcript
* Displaying insights
* Displaying risk decision
* Demonstrating automation usage

This layer does not contain AI logic.

---

# Input Contract (Person-1 → RAG Service)

The RAG service expects the following payload:

```
{
  "resolved_identity": {
    "loan_id": "LN102",
    "customer_id": "CUST45"
  },

  "cleaned_transcript": "salary late aaya emi pay nahi ho paaya next week kar dunga",

  "primary_insights": {
    "intent": {
      "label": "repayment_delay",
      "confidence": 0.92,
      "conditionality": "medium"
    },

    "sentiment": {
      "label": "stressed",
      "confidence": 0.88
    },

    "entities": {
      "payment_commitment": "next_week",
      "amount_mentioned": null
    },

    "risk_indicators": [
      "missed_emi",
      "salary_delay"
    ]
  },

  "summary_for_embedding": "Customer missed EMI due to salary delay and promised to make payment next week."
}
```

IMPORTANT:

* `call_id` is auto-generated by the RAG service (format: `call_{date}_{short_uuid}`)
* `call_timestamp` is auto-generated at ingestion time (server UTC)
* `loan_id` and `customer_id` are nested under `resolved_identity` (can be null)
* `loan_id` is used for history retrieval
* `intent` is an object with `label`, `confidence`, and `conditionality`
* `sentiment` is an object with `label` and `confidence`
* `summary_for_embedding` is the document stored in vector memory
* transcript is stored but NOT embedded

---

# Database Design (Supabase + pgvector)

We use two tables.

---

## calls table (metadata)

Fields:

* call_id (primary key)
* loan_id
* customer_id
* call_timestamp
* extracted_insights (JSONB)
* summary
* final_risk
* created_at

This stores structured interaction history.

---

## call_embeddings table (vector memory)

Fields:

* embedding_id
* call_id
* loan_id
* embedding (vector)
* summary_text
* created_at

This stores semantic memory for RAG retrieval.

---

# RAG Pipeline Lifecycle

The RAG service executes the following steps.

---

## Step 1 — Receive Call Insights

Input arrives from Person-1 service.

---

## Step 2 — Store Metadata

Insert record into `calls` table.

---

## Step 3 — Generate Embedding

Embed `summary_for_embedding`.

---

## Step 4 — Store Vector Memory

Insert into `call_embeddings`.

---

## Step 5 — Retrieve History

Two retrieval strategies are used:

### A. Loan timeline retrieval

Retrieve last N calls using loan_id.

Purpose:
Detect repeated repayment behavior.

### B. Semantic retrieval

Vector similarity search within same loan_id.

Purpose:
Retrieve similar financial situations.

---

## Step 6 — Context Builder

Construct reasoning context from:

* current insights
* last N calls
* similar past calls

This becomes the RAG context.

---

## Step 7 — LLM Risk Reasoning

The reasoning engine outputs:

* risk level
* explanation
* confidence

Example:
"Customer delayed EMI in 3 recent calls."

---

## Step 8 — Update Call Record

Update `calls.final_risk`.

---

## Step 9 — Optional Sponsor Integration

Backboard AI can be used to:

* store reasoning traces
* store case summaries
* store contextual knowledge

This is optional but beneficial.

---

# System Flow

End-to-end flow:

Audio
→ STT
→ NLP extraction
→ JSON payload
→ RAG service
→ Supabase storage
→ pgvector memory
→ history retrieval
→ reasoning
→ risk decision
→ frontend display

---

# Design Principles

The system follows these principles:

1. Identity comes from loan_id, not voice
2. Summaries are embedded, not transcripts
3. Metadata and vectors are stored separately
4. Retrieval uses both SQL and vector search
5. Reasoning must be explainable
6. RAG is used for decision support, not transcription

---

# Expected Final Output

The system should produce:

```
Intent: repayment_delay
Sentiment: stressed
Risk: HIGH
Explanation: Repeated EMI delay across recent calls
Confidence: 0.82
```

---

# MVP Scope

The MVP must include:

* Supabase tables
* pgvector embeddings
* summary embedding pipeline
* history retrieval
* reasoning step
* risk output

Optional:

* Backboard AI logging
* workflow integration
* advanced UI

---

# Developer Notes

If something breaks:

1. Verify input payload format
2. Verify summary generation
3. Verify embedding insertion
4. Verify retrieval queries
5. Verify reasoning context

Most bugs occur in retrieval logic.

---

# End of Context File

This document defines the entire project context.
