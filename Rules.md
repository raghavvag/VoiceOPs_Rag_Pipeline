# Financial Audio Intelligence — Project Context (v2)

## Purpose of This File

This file is the **single source of truth** for the project.

If any developer, IDE agent, or teammate is confused about architecture,
responsibilities, data flow, or RAG behavior — refer to this file.

---

# Project Overview

We are building a system that:

1. Processes financial call recordings (multilingual)
2. Extracts risk signals using NLP (done by Person-1 service)
3. Grounds those signals against known fraud/compliance patterns (RAG service)
4. Produces explainable, defensible risk assessments
5. Recommends policy-aware actions

This is NOT a customer memory system.
This is a **call-centric risk grounding system**.

Each call is treated as an **independent risk event**.

---

# Architectural Pivot (Why This Changed)

**Old approach:** Track customer identity over time → predict repayment risk.
**New approach:** Ground each call's risk signals against curated knowledge.

Why:
- No cold start problem
- No identity dependency
- Directly aligned with "legal risk & unreliable commitments"
- Easier to explain and demo
- Safer from compliance perspective

---

# System Components

## 1. Person-1 Service (Audio + NLP)

Responsible for:
- Audio normalization and quality assessment
- Speaker diarization
- Financial transcription
- Intent classification
- Sentiment detection
- Entity extraction
- Contradiction detection
- Obligation strength assessment
- Risk scoring and fraud likelihood

This service sends a **structured risk JSON** to the RAG service.

---

## 2. RAG Service (Grounding + Reasoning) — OUR RESPONSIBILITY

Responsible for:
- Receiving structured risk signals
- Embedding `summary_for_rag` for knowledge retrieval
- Retrieving relevant fraud patterns, compliance rules, risk heuristics
- Building grounding context
- Running LLM to produce explainable assessments
- Ensuring regulatory-safe language
- Recommending actions

### What RAG Does
1. Grounds risk signals against known patterns
2. Converts signals into auditor-friendly narratives
3. Validates (never overrides) the NLP risk score
4. Recommends policy-aware actions
5. Ensures regulatory-safe language

### What RAG Does NOT Do
- ❌ Extract intent
- ❌ Detect sentiment
- ❌ Compute risk scores
- ❌ Detect contradictions
- ❌ Analyze raw transcript
- ❌ Remember customers
- ❌ Make final business decisions

If RAG does any of these, architecture is broken.

---

## 3. Frontend / Workflow Layer

Responsible for:
- Uploading audio
- Displaying NLP insights
- Displaying RAG grounded assessment
- Showing recommended actions

This layer does not contain AI logic.

---

# Input Contract (NLP Service → RAG Service)

```json
{
  "call_context": {
    "call_language": "hinglish",
    "call_quality": {
      "noise_level": "medium",
      "call_stability": "low",
      "speech_naturalness": "suspicious"
    }
  },

  "speaker_analysis": {
    "customer_only_analysis": true,
    "agent_influence_detected": false
  },

  "nlp_insights": {
    "intent": {
      "label": "repayment_promise",
      "confidence": 0.6,
      "conditionality": "high"
    },
    "sentiment": {
      "label": "stressed",
      "confidence": 0.82
    },
    "obligation_strength": "weak",
    "entities": {
      "payment_commitment": "next_week",
      "amount_mentioned": null
    },
    "contradictions_detected": true
  },

  "risk_signals": {
    "audio_trust_flags": [
      "low_call_stability",
      "unnatural_speech_pattern"
    ],
    "behavioral_flags": [
      "conditional_commitment",
      "evasive_responses",
      "statement_contradiction"
    ]
  },

  "risk_assessment": {
    "risk_score": 78,
    "fraud_likelihood": "high",
    "confidence": 0.81
  },

  "summary_for_rag": "Customer made a conditional repayment promise, showed stress, and contradicted earlier statements, which aligns with known high-risk call patterns."
}
```

IMPORTANT:
- `call_id` is auto-generated by RAG service
- `call_timestamp` is auto-generated at ingestion
- `risk_assessment` comes from NLP — RAG validates but NEVER overrides
- `summary_for_rag` is embedded for knowledge retrieval
- No customer identity tracking

---

# RAG Output Contract

```json
{
  "grounded_assessment": "high_risk",
  "explanation": "...",
  "recommended_action": "manual_review",
  "confidence": 0.85,
  "regulatory_flags": [],
  "matched_patterns": [
    "conditional_commitment_with_contradiction",
    "weak_obligation_with_evasion"
  ]
}
```

### Grounded Assessment Values
- `high_risk` — signals match known fraud/high-risk patterns
- `medium_risk` — some signals match, ambiguity present
- `low_risk` — signals do not match known risk patterns

### Recommended Action Values
- `auto_clear` — low risk, no action needed
- `flag_for_review` — some concerns, queue for review
- `manual_review` — high risk, requires human review
- `escalate_to_compliance` — regulatory concerns detected

### Language Rules
- ❌ Never: "fraudster", "liar", "criminal"
- ✅ Always: "high-risk indicators", "unreliable commitment", "requires verification"

---

# Database Design (Supabase + pgvector)

Two tables.

## call_analyses table
- call_id (primary key, auto-generated)
- call_timestamp
- call_context (JSONB)
- speaker_analysis (JSONB)
- nlp_insights (JSONB)
- risk_signals (JSONB)
- risk_assessment (JSONB)
- summary_for_rag (TEXT)
- rag_output (JSONB)
- created_at

## knowledge_embeddings table
- doc_id (primary key)
- category (fraud_pattern / compliance / risk_heuristic)
- title
- content
- embedding (vector 1536)
- metadata (JSONB)
- created_at

---

# RAG Pipeline Lifecycle

1. Receive structured risk JSON from NLP service
2. Store call record in `call_analyses`
3. Embed `summary_for_rag` (query vector, not stored)
4. Retrieve knowledge chunks (fraud patterns, compliance, heuristics)
5. Build grounding context (signals + knowledge)
6. LLM produces grounded assessment with explanation
7. Store `rag_output` in call record
8. Return response

---

# Design Principles

1. Each call is independent — no customer memory
2. RAG grounds, it does not compute
3. Risk score comes from NLP — RAG validates, never overrides
4. Knowledge base is curated, not auto-generated
5. Explanations must be auditor-friendly
6. Language must be regulatory-safe
7. Recommendations are actions, not decisions

---

# One-Line Explanation

> "RAG grounds call-level risk signals against known fraud patterns and regulatory guidance, turning raw model outputs into explainable and defensible assessments."

---

# End of Context File
